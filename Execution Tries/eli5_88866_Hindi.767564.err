
Lmod is automatically replacing "gnu9/9.3.0" with "gnu10/10.3.0-ya".


Inactive Modules:
  1) hwloc/2.1.0     2) libfabric     3) openmpi4     4) ucx

2023-05-06 22:06:54.089487: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-06 22:06:56.653657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Tracking run with wandb version 0.15.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  5.51it/s]100%|██████████| 3/3 [00:00<00:00, 15.34it/s]
loading configuration file config.json from cache at /home/sshukla7/.cache/huggingface/hub/models--facebook--mbart-large-cc25/snapshots/f417e5563320b2cc8aabe4329d986b238809067f/config.json
Model config MBartConfig {
  "_name_or_path": "facebook/mbart-large-cc25",
  "_num_labels": 3,
  "activation_dropout": 0.0,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": true,
  "architectures": [
    "MBartForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "classifier_dropout": 0.0,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "dropout": 0.1,
  "encoder_attention_heads": 16,
  "encoder_ffn_dim": 4096,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 12,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_length": 1024,
  "max_position_embeddings": 1024,
  "model_type": "mbart",
  "normalize_before": true,
  "normalize_embedding": true,
  "num_beams": 5,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "scale_embedding": true,
  "static_position_embeddings": false,
  "task_specific_params": {
    "translation_en_to_ro": {
      "decoder_start_token_id": 250020
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 250027
}

Could not locate the tokenizer configuration file, will try to use the model config instead.
loading configuration file config.json from cache at /home/sshukla7/.cache/huggingface/hub/models--facebook--mbart-large-cc25/snapshots/f417e5563320b2cc8aabe4329d986b238809067f/config.json
Model config MBartConfig {
  "_name_or_path": "facebook/mbart-large-cc25",
  "_num_labels": 3,
  "activation_dropout": 0.0,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": true,
  "architectures": [
    "MBartForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "classifier_dropout": 0.0,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "dropout": 0.1,
  "encoder_attention_heads": 16,
  "encoder_ffn_dim": 4096,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 12,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_length": 1024,
  "max_position_embeddings": 1024,
  "model_type": "mbart",
  "normalize_before": true,
  "normalize_embedding": true,
  "num_beams": 5,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "scale_embedding": true,
  "static_position_embeddings": false,
  "task_specific_params": {
    "translation_en_to_ro": {
      "decoder_start_token_id": 250020
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 250027
}

loading file sentencepiece.bpe.model from cache at /home/sshukla7/.cache/huggingface/hub/models--facebook--mbart-large-cc25/snapshots/f417e5563320b2cc8aabe4329d986b238809067f/sentencepiece.bpe.model
loading file tokenizer.json from cache at /home/sshukla7/.cache/huggingface/hub/models--facebook--mbart-large-cc25/snapshots/f417e5563320b2cc8aabe4329d986b238809067f/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at None
loading file tokenizer_config.json from cache at None
loading configuration file config.json from cache at /home/sshukla7/.cache/huggingface/hub/models--facebook--mbart-large-cc25/snapshots/f417e5563320b2cc8aabe4329d986b238809067f/config.json
Model config MBartConfig {
  "_name_or_path": "facebook/mbart-large-cc25",
  "_num_labels": 3,
  "activation_dropout": 0.0,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": true,
  "architectures": [
    "MBartForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "classifier_dropout": 0.0,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "dropout": 0.1,
  "encoder_attention_heads": 16,
  "encoder_ffn_dim": 4096,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 12,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_length": 1024,
  "max_position_embeddings": 1024,
  "model_type": "mbart",
  "normalize_before": true,
  "normalize_embedding": true,
  "num_beams": 5,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "scale_embedding": true,
  "static_position_embeddings": false,
  "task_specific_params": {
    "translation_en_to_ro": {
      "decoder_start_token_id": 250020
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 250027
}

Assigning ['ar_AR', 'cs_CZ', 'de_DE', 'en_XX', 'es_XX', 'et_EE', 'fi_FI', 'fr_XX', 'gu_IN', 'hi_IN', 'it_IT', 'ja_XX', 'kk_KZ', 'ko_KR', 'lt_LT', 'lv_LV', 'my_MM', 'ne_NP', 'nl_XX', 'ro_RO', 'ru_RU', 'si_LK', 'tr_TR', 'vi_VN', 'zh_CN'] to the additional_special_tokens key of the tokenizer
Model config MBartConfig {
  "_name_or_path": "facebook/mbart-large-cc25",
  "_num_labels": 3,
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "MBartForConditionalGeneration"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.1,
  "classifier_dropout": 0.0,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "encoder_attention_heads": 16,
  "encoder_ffn_dim": 4096,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 12,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_length": 1024,
  "max_position_embeddings": 1024,
  "model_type": "mbart",
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "scale_embedding": true,
  "static_position_embeddings": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    }
  },
  "transformers_version": "4.28.1",
  "use_cache": true,
  "vocab_size": 250027
}

loading weights file pytorch_model.bin from cache at /home/sshukla7/.cache/huggingface/hub/models--facebook--mbart-large-cc25/snapshots/f417e5563320b2cc8aabe4329d986b238809067f/pytorch_model.bin
Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 4,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}

All model checkpoint weights were used when initializing MBartForConditionalGeneration.

All the weights of MBartForConditionalGeneration were initialized from the model checkpoint at facebook/mbart-large-cc25.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MBartForConditionalGeneration for predictions without further training.
loading configuration file generation_config.json from cache at /home/sshukla7/.cache/huggingface/hub/models--facebook--mbart-large-cc25/snapshots/f417e5563320b2cc8aabe4329d986b238809067f/generation_config.json
Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}

/home/sshukla7/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:649: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'
  warnings.warn(
Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}

/home/sshukla7/.local/lib/python3.10/site-packages/accelerate/accelerator.py:498: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.
  warnings.warn(
/home/sshukla7/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/sshukla7/sshukla7/DQ_BART/run_summarization_no_trainer_eli5Hindi.py:725: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric("rouge")
  0%|          | 0/630 [00:00<?, ?it/s]You're using a MBartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/630 [00:03<33:23,  3.18s/it]  1%|          | 5/630 [00:05<10:24,  1.00it/s]  1%|▏         | 9/630 [00:08<08:10,  1.27it/s]  2%|▏         | 13/630 [00:10<07:20,  1.40it/s]  3%|▎         | 17/630 [00:13<06:54,  1.48it/s]  3%|▎         | 21/630 [00:15<06:38,  1.53it/s]  4%|▍         | 25/630 [00:17<06:28,  1.56it/s]  5%|▍         | 29/630 [00:20<06:20,  1.58it/s]  5%|▌         | 33/630 [00:22<06:14,  1.60it/s]  6%|▌         | 37/630 [00:25<06:09,  1.61it/s]  7%|▋         | 41/630 [00:27<06:05,  1.61it/s]  7%|▋         | 45/630 [00:30<06:02,  1.61it/s]  8%|▊         | 49/630 [00:32<05:59,  1.62it/s]  8%|▊         | 53/630 [00:35<05:56,  1.62it/s]  9%|▉         | 57/630 [00:37<05:53,  1.62it/s] 10%|▉         | 61/630 [00:40<05:50,  1.62it/s]
  0%|          | 0/50 [00:00<?, ?it/s][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


  2%|▏         | 1/50 [00:14<11:42, 14.34s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}

 10%|█         | 63/630 [00:56<05:49,  1.62it/s]
  4%|▍         | 2/50 [00:27<10:55, 13.65s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


  6%|▌         | 3/50 [00:40<10:28, 13.38s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


  8%|▊         | 4/50 [00:53<10:11, 13.29s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 10%|█         | 5/50 [01:06<09:55, 13.23s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 12%|█▏        | 6/50 [01:19<09:40, 13.19s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 14%|█▍        | 7/50 [01:33<09:26, 13.18s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 16%|█▌        | 8/50 [01:46<09:12, 13.17s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 18%|█▊        | 9/50 [01:59<08:58, 13.14s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 20%|██        | 10/50 [02:12<08:45, 13.14s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 22%|██▏       | 11/50 [02:25<08:32, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 24%|██▍       | 12/50 [02:38<08:19, 13.14s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 26%|██▌       | 13/50 [02:51<08:05, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 28%|██▊       | 14/50 [03:04<07:52, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 30%|███       | 15/50 [03:18<07:39, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 32%|███▏      | 16/50 [03:31<07:26, 13.12s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 34%|███▍      | 17/50 [03:44<07:12, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 36%|███▌      | 18/50 [03:57<06:59, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 38%|███▊      | 19/50 [04:10<06:46, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 40%|████      | 20/50 [04:23<06:33, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 42%|████▏     | 21/50 [04:36<06:20, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 44%|████▍     | 22/50 [04:49<06:08, 13.14s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 46%|████▌     | 23/50 [05:03<05:54, 13.14s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 48%|████▊     | 24/50 [05:16<05:41, 13.15s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 50%|█████     | 25/50 [05:29<05:28, 13.14s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 52%|█████▏    | 26/50 [05:42<05:15, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 54%|█████▍    | 27/50 [05:55<05:01, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 56%|█████▌    | 28/50 [06:08<04:48, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 58%|█████▊    | 29/50 [06:21<04:35, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 60%|██████    | 30/50 [06:34<04:22, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 62%|██████▏   | 31/50 [06:48<04:08, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 64%|██████▍   | 32/50 [07:01<03:56, 13.13s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 66%|██████▌   | 33/50 [07:14<03:42, 13.12s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 68%|██████▊   | 34/50 [07:27<03:29, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 70%|███████   | 35/50 [07:40<03:16, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 72%|███████▏  | 36/50 [07:53<03:03, 13.09s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 74%|███████▍  | 37/50 [08:06<02:50, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 76%|███████▌  | 38/50 [08:19<02:37, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 78%|███████▊  | 39/50 [08:32<02:24, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 80%|████████  | 40/50 [08:45<02:11, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 82%|████████▏ | 41/50 [08:59<01:57, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 84%|████████▍ | 42/50 [09:12<01:44, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 86%|████████▌ | 43/50 [09:25<01:31, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 88%|████████▊ | 44/50 [09:38<01:18, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 90%|█████████ | 45/50 [09:51<01:05, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 92%|█████████▏| 46/50 [10:04<00:52, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 94%|█████████▍| 47/50 [10:17<00:39, 13.10s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 96%|█████████▌| 48/50 [10:30<00:26, 13.11s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


 98%|█████████▊| 49/50 [10:43<00:13, 13.12s/it][AGenerate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "max_length": 1024,
  "num_beams": 5,
  "pad_token_id": 1,
  "transformers_version": "4.28.1"
}


100%|██████████| 50/50 [10:57<00:00, 13.11s/it][A100%|██████████| 50/50 [10:57<00:00, 13.14s/it]
Traceback (most recent call last):
  File "/home/sshukla7/sshukla7/DQ_BART/run_summarization_no_trainer_eli5Hindi.py", line 1003, in <module>
    main()
  File "/home/sshukla7/sshukla7/DQ_BART/run_summarization_no_trainer_eli5Hindi.py", line 929, in main
    unwrapped_model.save_pretrained(args.output_dir, save_function=accelerator.save)
  File "/home/sshukla7/.local/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1756, in save_pretrained
    model_to_save.config.save_pretrained(save_directory)
  File "/home/sshukla7/.local/lib/python3.10/site-packages/transformers/configuration_utils.py", line 456, in save_pretrained
    self.to_json_file(output_config_file, use_diff=True)
TypeError: BartConfig.to_json_file() got an unexpected keyword argument 'use_diff'
wandb: Waiting for W&B process to finish... (failed 1).
wandb: 
wandb: Run history:
wandb:             eval/rouge1 ▁
wandb:             eval/rouge2 ▁
wandb:             eval/rougeL ▁
wandb:          eval/rougeLsum ▁
wandb:      train/crs_att_loss ▂█▁
wandb:      train/dec_att_loss █▅▁
wandb:      train/dec_hid_loss ▂▁█
wandb:      train/enc_att_loss █▅▁
wandb: train/enc_hid_last_loss ▇█▁
wandb:      train/enc_hid_loss ▁█▂
wandb:       train/logits_loss █▂▁
wandb:              train/loss █▁▁
wandb:                train/lr ▁█▇
wandb:              train/step ▁▅█
wandb:         train/task_loss █▂▁
wandb: 
wandb: Run summary:
wandb:             eval/rouge1 0.1043
wandb:             eval/rouge2 0.0
wandb:             eval/rougeL 0.1048
wandb:          eval/rougeLsum 0.1051
wandb:      train/crs_att_loss 1.60142
wandb:      train/dec_att_loss 0.01852
wandb:      train/dec_hid_loss 668.72789
wandb:      train/enc_att_loss 0.05694
wandb: train/enc_hid_last_loss 3.48089
wandb:      train/enc_hid_loss 115.61986
wandb:       train/logits_loss 428.35459
wandb:              train/loss 1227.37196
wandb:                train/lr 5e-05
wandb:              train/step 59
wandb:         train/task_loss 11.0332
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/sshukla7/sshukla7/DQ_BART/wandb/offline-run-20230506_220705-4xanvx17
wandb: Find logs at: ./wandb/offline-run-20230506_220705-4xanvx17/logs
