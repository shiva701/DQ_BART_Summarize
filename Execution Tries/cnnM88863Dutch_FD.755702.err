
Lmod is automatically replacing "gnu9/9.3.0" with "gnu10/10.3.0-ya".


Inactive Modules:
  1) hwloc/2.1.0     2) libfabric     3) openmpi4     4) ucx

2023-05-01 14:03:43.764979: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-01 14:03:46.407486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Tracking run with wandb version 0.15.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:01,  1.62it/s]100%|██████████| 3/3 [00:00<00:00,  4.42it/s]
https://huggingface.co/facebook/mbart-large-50/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/sshukla7/.cache/huggingface/transformers/tmpkjfiptdd
Downloading:   0%|          | 0.00/1.38k [00:00<?, ?B/s]Downloading: 100%|██████████| 1.38k/1.38k [00:00<00:00, 3.56MB/s]
storing https://huggingface.co/facebook/mbart-large-50/resolve/main/config.json in cache at /home/sshukla7/.cache/huggingface/transformers/f05465e59eda7f301b62d284f0aff5987c4eafb42ddef0f71b9a8e4c4f6e00f2.b12b1c70d50e4d5e2fcb7773b69c8bbdd6d9f2e18e435c2b368caea016a3ef77
creating metadata file for /home/sshukla7/.cache/huggingface/transformers/f05465e59eda7f301b62d284f0aff5987c4eafb42ddef0f71b9a8e4c4f6e00f2.b12b1c70d50e4d5e2fcb7773b69c8bbdd6d9f2e18e435c2b368caea016a3ef77
loading configuration file https://huggingface.co/facebook/mbart-large-50/resolve/main/config.json from cache at /home/sshukla7/.cache/huggingface/transformers/f05465e59eda7f301b62d284f0aff5987c4eafb42ddef0f71b9a8e4c4f6e00f2.b12b1c70d50e4d5e2fcb7773b69c8bbdd6d9f2e18e435c2b368caea016a3ef77
Model config MBartConfig {
  "_name_or_path": "facebook/mbart-large-50",
  "_num_labels": 3,
  "activation_dropout": 0.0,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": true,
  "architectures": [
    "MBartForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "classifier_dropout": 0.0,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 16,
  "encoder_ffn_dim": 4096,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 12,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_length": 200,
  "max_position_embeddings": 1024,
  "model_type": "mbart",
  "normalize_before": true,
  "normalize_embedding": true,
  "num_beams": 5,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "scale_embedding": true,
  "static_position_embeddings": false,
  "tokenizer_class": "MBart50Tokenizer",
  "transformers_version": "4.17.0",
  "use_cache": true,
  "vocab_size": 250054
}

https://huggingface.co/facebook/mbart-large-50/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /home/sshukla7/.cache/huggingface/transformers/tmpq85e4nfp
Downloading:   0%|          | 0.00/531 [00:00<?, ?B/s]Downloading: 100%|██████████| 531/531 [00:00<00:00, 1.40MB/s]
storing https://huggingface.co/facebook/mbart-large-50/resolve/main/tokenizer_config.json in cache at /home/sshukla7/.cache/huggingface/transformers/daff1f01b888a47cdbe3d56766d2468e76d8d6cff9661b84ae0d57a3eb10732e.a94e252ee9791a9d77f2cef0e43c636de01335ae4b9d98087c92dc320b682dca
creating metadata file for /home/sshukla7/.cache/huggingface/transformers/daff1f01b888a47cdbe3d56766d2468e76d8d6cff9661b84ae0d57a3eb10732e.a94e252ee9791a9d77f2cef0e43c636de01335ae4b9d98087c92dc320b682dca
loading configuration file https://huggingface.co/facebook/mbart-large-50/resolve/main/config.json from cache at /home/sshukla7/.cache/huggingface/transformers/f05465e59eda7f301b62d284f0aff5987c4eafb42ddef0f71b9a8e4c4f6e00f2.b12b1c70d50e4d5e2fcb7773b69c8bbdd6d9f2e18e435c2b368caea016a3ef77
Model config MBartConfig {
  "_name_or_path": "facebook/mbart-large-50",
  "_num_labels": 3,
  "activation_dropout": 0.0,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": true,
  "architectures": [
    "MBartForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "classifier_dropout": 0.0,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 16,
  "encoder_ffn_dim": 4096,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 12,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_length": 200,
  "max_position_embeddings": 1024,
  "model_type": "mbart",
  "normalize_before": true,
  "normalize_embedding": true,
  "num_beams": 5,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "scale_embedding": true,
  "static_position_embeddings": false,
  "tokenizer_class": "MBart50Tokenizer",
  "transformers_version": "4.17.0",
  "use_cache": true,
  "vocab_size": 250054
}

https://huggingface.co/facebook/mbart-large-50/resolve/main/sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /home/sshukla7/.cache/huggingface/transformers/tmp4c99ebnl
Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]Downloading: 100%|██████████| 4.83M/4.83M [00:00<00:00, 105MB/s]
storing https://huggingface.co/facebook/mbart-large-50/resolve/main/sentencepiece.bpe.model in cache at /home/sshukla7/.cache/huggingface/transformers/67d3c795fa98268609962dbbd51f9c2a532a92638ad74e79dfed71791af90217.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e
creating metadata file for /home/sshukla7/.cache/huggingface/transformers/67d3c795fa98268609962dbbd51f9c2a532a92638ad74e79dfed71791af90217.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e
https://huggingface.co/facebook/mbart-large-50/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /home/sshukla7/.cache/huggingface/transformers/tmpgxikd3p0
Downloading:   0%|          | 0.00/649 [00:00<?, ?B/s]Downloading: 100%|██████████| 649/649 [00:00<00:00, 888kB/s]
storing https://huggingface.co/facebook/mbart-large-50/resolve/main/special_tokens_map.json in cache at /home/sshukla7/.cache/huggingface/transformers/b84d4a0379a665c99c99c99a288e32cc76d92f6d30d0546b6c561c9c6f583946.ac77c0b56ab82aca841e254aa35803773ca3f42af7b173cc9e56af3bc76083d0
creating metadata file for /home/sshukla7/.cache/huggingface/transformers/b84d4a0379a665c99c99c99a288e32cc76d92f6d30d0546b6c561c9c6f583946.ac77c0b56ab82aca841e254aa35803773ca3f42af7b173cc9e56af3bc76083d0
loading file https://huggingface.co/facebook/mbart-large-50/resolve/main/sentencepiece.bpe.model from cache at /home/sshukla7/.cache/huggingface/transformers/67d3c795fa98268609962dbbd51f9c2a532a92638ad74e79dfed71791af90217.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e
loading file https://huggingface.co/facebook/mbart-large-50/resolve/main/tokenizer.json from cache at None
loading file https://huggingface.co/facebook/mbart-large-50/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/facebook/mbart-large-50/resolve/main/special_tokens_map.json from cache at /home/sshukla7/.cache/huggingface/transformers/b84d4a0379a665c99c99c99a288e32cc76d92f6d30d0546b6c561c9c6f583946.ac77c0b56ab82aca841e254aa35803773ca3f42af7b173cc9e56af3bc76083d0
loading file https://huggingface.co/facebook/mbart-large-50/resolve/main/tokenizer_config.json from cache at /home/sshukla7/.cache/huggingface/transformers/daff1f01b888a47cdbe3d56766d2468e76d8d6cff9661b84ae0d57a3eb10732e.a94e252ee9791a9d77f2cef0e43c636de01335ae4b9d98087c92dc320b682dca
loading configuration file https://huggingface.co/facebook/mbart-large-50/resolve/main/config.json from cache at /home/sshukla7/.cache/huggingface/transformers/f05465e59eda7f301b62d284f0aff5987c4eafb42ddef0f71b9a8e4c4f6e00f2.b12b1c70d50e4d5e2fcb7773b69c8bbdd6d9f2e18e435c2b368caea016a3ef77
Model config MBartConfig {
  "_name_or_path": "facebook/mbart-large-50",
  "_num_labels": 3,
  "activation_dropout": 0.0,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": true,
  "architectures": [
    "MBartForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classif_dropout": 0.0,
  "classifier_dropout": 0.0,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 16,
  "encoder_ffn_dim": 4096,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 12,
  "eos_token_id": 2,
  "forced_eos_token_id": 2,
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "max_length": 200,
  "max_position_embeddings": 1024,
  "model_type": "mbart",
  "normalize_before": true,
  "normalize_embedding": true,
  "num_beams": 5,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "scale_embedding": true,
  "static_position_embeddings": false,
  "tokenizer_class": "MBart50Tokenizer",
  "transformers_version": "4.17.0",
  "use_cache": true,
  "vocab_size": 250054
}

Traceback (most recent call last):
  File "/home/sshukla7/sshukla7/DQ_BART/run_summarization_no_trainer_cnnDutch.py", line 946, in <module>
    main()
  File "/home/sshukla7/sshukla7/DQ_BART/run_summarization_no_trainer_cnnDutch.py", line 460, in main
    tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, use_fast=not args.use_slow_tokenizer)
  File "/home/sshukla7/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 528, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/sshukla7/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1788, in from_pretrained
    return cls._from_pretrained(
  File "/home/sshukla7/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1923, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/sshukla7/.local/lib/python3.10/site-packages/transformers/models/mbart50/tokenization_mbart50_fast.py", line 135, in __init__
    super().__init__(
  File "/home/sshukla7/.local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py", line 119, in __init__
    raise ValueError(
ValueError: Couldn't instantiate the backend tokenizer from one of: 
(1) a `tokenizers` library serialization file, 
(2) a slow tokenizer instance to convert or 
(3) an equivalent slow tokenizer class to instantiate and convert. 
You need to have sentencepiece installed to convert a slow tokenizer to a fast one.
wandb: Waiting for W&B process to finish... (failed 1).
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/sshukla7/sshukla7/DQ_BART/wandb/offline-run-20230501_140352-lbxam5kk
wandb: Find logs at: ./wandb/offline-run-20230501_140352-lbxam5kk/logs
